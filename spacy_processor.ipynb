{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spacy_processor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SergeyKamenshchikov/CORONA/blob/master/spacy_processor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuXsSvu_7Ork",
        "colab_type": "text"
      },
      "source": [
        "Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHz4Q-LRm63l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1e8ad4cb-4405-467f-80c3-402cca264c2e"
      },
      "source": [
        "!pip3 install allennlp==1.0.0 allennlp-models==1.0.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting allennlp==1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/49/bf0ec241496a82c9dd2f0b6ff6f8156b6b2b72b849df8c00a4f2bcf61485/allennlp-1.0.0-py3-none-any.whl (473kB)\n",
            "\u001b[K     |████████████████████████████████| 481kB 4.4MB/s \n",
            "\u001b[?25hCollecting allennlp-models==1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/d5/9ee1d0b8c217b6978e42e54fbab8bafe9e792f0f8262f381dde44cee44ae/allennlp_models-1.0.0-py3-none-any.whl (282kB)\n",
            "\u001b[K     |████████████████████████████████| 286kB 13.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (2.10.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (1.18.5)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (2.23.0)\n",
            "Collecting jsonnet>=0.10.0; sys_platform != \"win32\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/70/ed1ba808a87d896b9f4d25400dda54e089ca7a97e87cee620b3744997c89/jsonnet-0.16.0.tar.gz (256kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 14.7MB/s \n",
            "\u001b[?25hCollecting torch<1.6.0,>=1.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/01/457b49d790b6c4b9720e6f9dbbb617692f6ce8afdaadf425c055c41a7416/torch-1.5.1-cp36-cp36m-manylinux1_x86_64.whl (753.2MB)\n",
            "\u001b[K     |████████████████████████████████| 753.2MB 19kB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock<3.1,>=3.0 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (3.0.12)\n",
            "Collecting jsonpickle\n",
            "  Downloading https://files.pythonhosted.org/packages/af/ca/4fee219cc4113a5635e348ad951cf8a2e47fed2e3342312493f5b73d0007/jsonpickle-1.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: spacy<2.3,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (2.2.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (1.14.48)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (3.6.4)\n",
            "Collecting overrides==3.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/42/8d/caa729f809ecdf8e76fac3c1ff7d3f0b72c398c9dd8a6919927a30a873b3/overrides-3.0.0.tar.gz\n",
            "Collecting tensorboardX>=1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 40.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (0.7)\n",
            "Collecting transformers<2.12,>=2.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\u001b[K     |████████████████████████████████| 675kB 39.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (0.22.2.post1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (3.2.5)\n",
            "Collecting word2number>=1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/4a/29/a31940c848521f0725f0df6b25dca8917f13a2025b0e8fcbe5d0457e45e6/word2number-1.1.zip\n",
            "Collecting py-rouge==1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/1d/0bdbaf559fb7afe32308ebc84a2028600988212d7eb7fb9f69c4e829e4a0/py_rouge-1.1-py3-none-any.whl (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.4MB/s \n",
            "\u001b[?25hCollecting conllu==3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/66/0b/a8863b5c14aee200a13a0f8c28550fd0132e947ae88441c9f517eb84613b/conllu-3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->allennlp==1.0.0) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==1.0.0) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==1.0.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==1.0.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==1.0.0) (2.10)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<1.6.0,>=1.5.0->allennlp==1.0.0) (0.16.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from jsonpickle->allennlp==1.0.0) (1.7.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (2.0.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (3.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (0.7.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (49.6.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (1.0.0)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.48 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp==1.0.0) (1.17.48)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp==1.0.0) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp==1.0.0) (0.10.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0) (8.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0) (1.9.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0) (20.1.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0) (0.7.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp==1.0.0) (3.12.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 36.3MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 42.6MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 34.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<2.12,>=2.9->allennlp==1.0.0) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<2.12,>=2.9->allennlp==1.0.0) (2019.12.20)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->allennlp==1.0.0) (0.16.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->jsonpickle->allennlp==1.0.0) (3.1.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.48->boto3->allennlp==1.0.0) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.48->boto3->allennlp==1.0.0) (2.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<2.12,>=2.9->allennlp==1.0.0) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<2.12,>=2.9->allennlp==1.0.0) (2.4.7)\n",
            "Building wheels for collected packages: jsonnet, overrides, word2number, sacremoses\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.16.0-cp36-cp36m-linux_x86_64.whl size=3321641 sha256=251f92e6ca75494f1a6e1e4d8830f134a30c05a042f0b0dec2285202b8921580\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/a9/43/bc5e0463deeec89dfca928a2a64595f1bdb520c891f6fbd09c\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.0.0-cp36-none-any.whl size=5669 sha256=d246177b59a5a5050c977db0d57b89c02455d1080018bf74c67b3e064c0b4349\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/1b/ec/6c71a1eb823df7f850d956b2d8c50a6d49c191e1063d73b9be\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-cp36-none-any.whl size=5588 sha256=33fc3ef1c2de58e809892fa43b0d734213ddb8a14f564130a3de32c591e5646b\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/2f/53/5f5c1d275492f2fce1cdab9a9bb12d49286dead829a4078e0e\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=4e12ac0f6cbcb42a9243490d52377af7688756a7ac79b7040d018a4d93d2c506\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built jsonnet overrides word2number sacremoses\n",
            "\u001b[31mERROR: torchvision 0.7.0+cu101 has requirement torch==1.6.0, but you'll have torch 1.5.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jsonnet, torch, jsonpickle, overrides, tensorboardX, sacremoses, sentencepiece, tokenizers, transformers, allennlp, word2number, py-rouge, conllu, allennlp-models\n",
            "  Found existing installation: torch 1.6.0+cu101\n",
            "    Uninstalling torch-1.6.0+cu101:\n",
            "      Successfully uninstalled torch-1.6.0+cu101\n",
            "Successfully installed allennlp-1.0.0 allennlp-models-1.0.0 conllu-3.0 jsonnet-0.16.0 jsonpickle-1.4.1 overrides-3.0.0 py-rouge-1.1 sacremoses-0.0.43 sentencepiece-0.1.91 tensorboardX-2.1 tokenizers-0.7.0 torch-1.5.1 transformers-2.11.0 word2number-1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94_CB122nvKk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "6b94cf8a-f93b-4961-b8cb-cf0c386a2007"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "!wget https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2020.02.27.tar.gz"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "--2020-09-08 12:10:26--  https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2020.02.27.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.197.128, 74.125.142.128, 74.125.195.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.197.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1345947288 (1.3G) [application/x-tar]\n",
            "Saving to: ‘coref-spanbert-large-2020.02.27.tar.gz’\n",
            "\n",
            "coref-spanbert-larg 100%[===================>]   1.25G  14.5MB/s    in 85s     \n",
            "\n",
            "2020-09-08 12:11:52 (15.1 MB/s) - ‘coref-spanbert-large-2020.02.27.tar.gz’ saved [1345947288/1345947288]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-M9yhT-nCcG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f990b4f8-8cc1-4493-e577-0542f7c4796b"
      },
      "source": [
        "# import libraries\n",
        "import string\n",
        "from textblob import TextBlob\n",
        "from gensim.summarization.summarizer import summarize\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "en_stopwords = stopwords.words('english')\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import requests\n",
        "\n",
        "from allennlp.predictors.predictor import Predictor\n",
        "import allennlp_models.coref\n",
        "\n",
        "#!wget https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2020.02.27.tar.gz\n",
        "predictor = Predictor.from_path('./coref-spanbert-large-2020.02.27.tar.gz')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:allennlp.nn.initializers:Did not use initialization regex that was passed: _context_layer._module.weight_ih.*\n",
            "WARNING:allennlp.nn.initializers:Did not use initialization regex that was passed: _context_layer._module.weight_hh.*\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSXjkDiRoe8y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# customer defined functions\n",
        "def get_unique_text(document):\n",
        "    unique_sentences = []\n",
        "    for sentence in [sent.raw for sent in TextBlob(document).sentences]:\n",
        "        if sentence not in unique_sentences:\n",
        "            unique_sentences.append(sentence)\n",
        "    return ' '.join(unique_sentences)\n",
        "\n",
        "def get_summary(rawtext,readtime):\n",
        "    sentences = int(readtime/(np.median([len(i.split()) for i in nltk.sent_tokenize(rawtext)])/200))\n",
        "    ratio = sentences/len(nltk.sent_tokenize(rawtext))\n",
        "    txt = summarize(rawtext, ratio=ratio)\n",
        "\n",
        "    z = 0\n",
        "    output = []\n",
        "    for i in nltk.sent_tokenize(txt):\n",
        "        z = z+1\n",
        "        output.append('\\n\\n<hr>' + str(z) + '. ' + str(i))\n",
        "\n",
        "    txt = ' '.join(output)\n",
        "    return txt    "
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25mG38iso1Dw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2f9eb2c9-e8d1-4c86-af70-49c236d7fa3b"
      },
      "source": [
        "htmlString = requests.get('https://medium.com/@sergeykamenshchikov/nlp-for-composition-of-value-tree-d8495534ebd5')\n",
        "\n",
        "soup = BeautifulSoup(htmlString.content, 'html.parser')\n",
        "paragraphs = soup.find_all(['p', 'article', 'section', 'title', 'h1', 'h2', 'h3'])\n",
        "rawtext = ' '.join([i.text for i in paragraphs])\n",
        "rawtext=get_unique_text(rawtext)\n",
        "\n",
        "print(rawtext)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NLP for composition of Value Tree | by Sergey Kamenshchikov | Medium Responses  Sergey KamenshchikovFollowSep 29, 2019 · 6 min readTree of Keywords: graph analysis of semantics attractorsApplication domain. According to the WHO depressive disorder is the leading cause of disability worldwide. It is found that generating mechanism lies in rumination: long-term stressful attachment to the problem and underlying Super Value in danger. Efforts of predictive pattern recognition are made in several fields - Machine Learning is among them.Previous research. According to Al-Mosaiwi, single words-absolutisms may be used as predictors of cognitive errors following rumination. However it is recognized that analysis of single word frequencies is not enough. The reason is simple: random mixing of word collection does not affect the relative frequency, but removes information — bag of words effect. This means that the semantic source of rumination, value, is outside the scope. Besides, according to Kahneman and Tversky, any human may unconsciously switch on individual irrational schemes for making faster decisions: increase speed sacrificing rationality. However they admitted that this effect may be smoothed in group due to decorrelation of individual biases. The Researchers from MIT have developed and trained neural network, which predicts depression rate in clinical interviews with precision of 71% and recall of 83%. However they admit that their model discovers cognitive impairments as well, ignoring cognition structure.Assumptions. According to Relational Frame Theory (RFT) developed by psychologist Steven C. Hayes bidirectional links of entities are cognitive building elements. This psychological theory of human language states that reality is reached as a multidimensional graph in process of associative learning. Language is a mental projection into the entities space, while bigrams of entities express mental schemes. Studies validated that associative schemes are specific and stable for each individual. Pathological states like depression correspond to destructive associative schemes: specific graph clusters which trigger ruminative loops. We assume that these clusters may have high betweennes centrality (BC), clustering feature. Entities with extra high BC may be considered as information hubs, speech attractors, which influence the semantics in high extent. High number of ruminative clusters may rise up the integral betweennes centrality of graph. Recognition of ruminative clusters, their centers and undelying values are among the goals of this research. Decorrelation of biases, noticed by Kahneman and Tversky, suggests that differences in BC may be associated with communication intensity and group values. These hypotheses have been tested through the instance based model.Data preparation. According to the WHO Russia is number three in the age-standardized list of suicide rates. We explored the most popular Russian speaking Wall of Help: more than 150,000 visits per day. Traffic is distributed among Russia, Germany and UK. Top 3 search engine requests are: #depression, #meaning of life and #suicide. Responces are provided by psychotherapists, charity volunteers and common people.Age standartizationResponse/request collections have been parsed: 25,000 of records in 2018. Text cleaning includes age, sex, text length standardizations and abstract mining (first 100 words). Metric analysis and text cleaning were implemented with use of Python ecosystem including NetworkX and NLTK libraries. Sex standardization was reached with use of name — sex recognition. Morphological cleaning and tokenization allowed getting nouns in standard form. Stemming was applied as well to reduce dimension. Vocabulary of bigrams with corresponding frequences was mined. Bigram sets are ordered by frequency and normalized to equal volume by the cutoff criteria. Each group, Request/Responce, is characterized by unique bigram matrix. Increase of information as inverse to Shannon entropy is shown after the transition from single words to bigrams: 30% of increment. Further increase of n-gram length gave no significant increment: I(3)-I(2)=6% for the 3-grams, [H(4)-H(3)]=2% and less than 1% for N>4. It seems that bidirectional associations, proposed by RFT as the semantics blocks fit.Data compression. Сonversion was implemented by Open Ord force-directed layout algorithm — Gephi software was integrated with Python core. Bigram matrix was used as a generator of weighted undirected graph for interpretation of Big Data by psychologists at glance. Open Ord makes transformation from 2D matrix to the tree topology graph. Weight of each node in matrix corresponds to the single word frequency while edge length is the inverse function of bigram frequency. Nodes are ranged according to the betweennes centrality and marked at the transformed graph. Closest neighbours are based on co-occurrence frequency analysis. High BC node and its neighbours form the cluster.Open Ord TransformationResults. Deviation of BC across the graph D=|BC(max)-BC(mean)| was considered as the integral clustering metric. 43% of ordered bigrams have been used in both groups. Each graph is based on 10,000 most frequent bigrams. Comparison of Request/Responce graphs showed a significant difference in centralization: D(Request)/D(Responce)=1.7. Relatively high BC-clustering in the test group is validated by Zip’s law factor: 47 in Request Group against 25 in Responce Group, 1.9 times higher. Zip’s law was applied to unordered bigrams. The integral under the Zip’s curve is 1.5 times higher in the test group. It seems that ruminative clusters and bigrams in Request sample give significant input as it was expected.Standard deviation of sentence length is 1.7 times higher, which marks higher emotional instability of the test messages. Top 5 entities, arranged by BC are #Year, #Life, #Man, #Job, #Family/Procreation. Tags in figures are translated into English. #Year tag confirms a long-term stressful state, but is not interpreted as the Value. #Man, #Job, #Family/Procreation are considered in relation to the Root Value: #Life. Nearest neighbours technics is applied: keywords extraction in relation to the given topic#Man value is almost fused with #Life root-attractor in the Request Group. It remarks probable subjective/objective isolation and high need of qualitative social contacts. According to Kahneman and Tversky the isolation factor reinforce cognitive errors and reduces flexibility in communication. Harmful effects of isolation are already observed by psychotherapists. However it was not clear whether it plays the key role in suicidal tendencies. Method of irrational vocabulary was compared with the graph technique. Two lists of single word absolutisms and ‘shoulds’ were generated on the basis of Mosaiwi research. However it turned out that irrationality frequency is only 1,1 times higher in the request group vice the responce group. Fraction of messages, containing at least one word from irrational vocabulary is 84% against 78%. It seems that D(Request)/D(Responce) and Zip’s metrics are more sensitive and are closer to the trigger: rumination.Findings and interpretation. Bidirectional language associations, bigrams, are optimal semantics blocks and validates RFT assumptions. They provide 30% of information increment, comparing with single words analysis. Ruminative attractors provide sufficient increase of centralization metric: betweennes centrality. It is more sensitive than irrationality frequency despite the topic bias in the responce group. Instance analysis of text/speech and normalized BC may give insights about the suicidal risks without applying more complicated techniques like neural networks (NNs). Value analysis may be validated by fast visual interpretation in comparison to the “black box” rules of NNs. Ruminative clusters may be discovered directly: they are formed on the basis of Group Values (#Man) more than Undividual Values (#Job). Communication value may be underestimated in the standard protocols of depression cure. Its therapeutic effect may be explained in frame of bias smoothing. It should be noticed that betweennes centrality is the measure of ‘diversification’ as well. It means that over focus may be as risky for the psyche as ‘single-equity’ investment portfolio for your pension plan.Application rescaling. The given algorithm may be used for mining of core entities in frame of relative ranking. It provided rescale stability under the conditions of noisy reference text. The instrument may have applications in HR evaluation and speech keywords extraction: AI problems. Authors conduct relevant research and look for collaboration. The full version of research is pending in the peer reviewed journal. However you may ask draft upon the personal request.I would like to thank Doctor Ann Butkovskaya for psychological interpretation of results and co-authorship in full version article. Sergey KamenshchikovFollowSep 29, 2019 · 6 min read  Tree of Keywords: graph analysis of semantics attractorsApplication domain. Tree of Keywords: graph analysis of semantics attractors Application domain. Efforts of predictive pattern recognition are made in several fields - Machine Learning is among them. Previous research. However they admit that their model discovers cognitive impairments as well, ignoring cognition structure. Assumptions. These hypotheses have been tested through the instance based model. Data preparation. Responces are provided by psychotherapists, charity volunteers and common people. Response/request collections have been parsed: 25,000 of records in 2018. It seems that bidirectional associations, proposed by RFT as the semantics blocks fit. Data compression. High BC node and its neighbours form the cluster. Results. It seems that ruminative clusters and bigrams in Request sample give significant input as it was expected. Standard deviation of sentence length is 1.7 times higher, which marks higher emotional instability of the test messages. Nearest neighbours technics is applied: keywords extraction in relation to the given topic #Man value is almost fused with #Life root-attractor in the Request Group. It seems that D(Request)/D(Responce) and Zip’s metrics are more sensitive and are closer to the trigger: rumination. Findings and interpretation. It means that over focus may be as risky for the psyche as ‘single-equity’ investment portfolio for your pension plan. Application rescaling. However you may ask draft upon the personal request. I would like to thank Doctor Ann Butkovskaya for psychological interpretation of results and co-authorship in full version article. Written by Sergey Kamenshchikov Written by Sergey Kamenshchikov More From Medium Gauss Rank Transformation is 100x Faster with RAPIDS and CuPy Streaming Inference Pipeline — Deploying MXNet model on AWS Lambda Introduction to Generative Adversarial Networks (GANs) Hypothesis Testing How to Build a Dog Breed Classifier using CNN? Detecting Ships in Satellite Imagery TD Learning — Solving the evaluation problem PoseFlow — real-time pose tracking Discover Medium Make Medium yours Become a member\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IVUm-Leo65V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "92bca4bd-4911-49c5-c2a7-7b0aab8b29cd"
      },
      "source": [
        "#coreference resolution\n",
        "%%time\n",
        "span_dict=predictor.predict(document=rawtext)\n",
        "words=span_dict['document']\n",
        "\n",
        "original_document=span_dict['document']\n",
        "clusters=span_dict['clusters']\n",
        "\n",
        "for cluster in clusters:\n",
        "    first_element=cluster[0]\n",
        "    head=original_document[first_element[0]:first_element[1]+1] #get head of cluster\n",
        "    if len(head)==1 and head[0].lower() in en_stopwords: #check if pronoun\n",
        "        pass\n",
        "    else:\n",
        "        for element in cluster:\n",
        "            for index in range(element[0],element[1]+1):\n",
        "                words[index]='' #make all elements empty to save indexes of document words\n",
        "        for element in cluster:\n",
        "            words[element[0]]=\"\".join([\" \"+w if not w.startswith(\"'\") and w not in string.punctuation else w for w in head]).strip()\n",
        "\n",
        "document=\"\".join([\" \"+w if not w.startswith(\"'\") and w!='' and w not in string.punctuation else w for w in words]).strip()            "
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 15s, sys: 4.37 s, total: 1min 19s\n",
            "Wall time: 1min 19s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Y5pyqAfqA_6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "outputId": "5a825ef8-1527-4489-b511-d6c77019a821"
      },
      "source": [
        "final_summary = get_summary(document,2)\n",
        "print(final_summary)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "<hr>1. NLP for composition of Value Tree| by Sergey Kamenshchikov| Medium Responses   Sergey Kamenshchikov 29, 2019 · 6 min readTree of Keywords: graph analysis of semantics attractorsApplication domain. \n",
            "\n",
            "<hr>2. According to Al- Mosaiwi, single words- absolutisms may be used as predictors of cognitive errors following rumination. \n",
            "\n",
            "<hr>3. The Researchers from MIT have developed and trained neural network, which predicts depression rate in clinical interviews with precision of 71% and recall of 83%. \n",
            "\n",
            "<hr>4. However The Researchers from MIT admit that neural network, which predicts depression rate in clinical interviews with precision of 71% and recall of 83% discovers cognitive impairments as well, ignoring cognition structure. \n",
            "\n",
            "<hr>5. Pathological states like depression correspond to destructive associative schemes: specific graph clusters which trigger ruminative loops. \n",
            "\n",
            "<hr>6. We assume that specific graph clusters which trigger ruminative loops may have high betweennes centrality( BC), clustering feature. \n",
            "\n",
            "<hr>7. High number of ruminative clusters may rise up the integral betweennes centrality of graph. \n",
            "\n",
            "<hr>8. Decorrelation of biases, noticed by Kahneman and Tversky, suggests that differences in BC may be associated with communication intensity and group values. \n",
            "\n",
            "<hr>9. Increase of information as inverse to Shannon entropy is shown after the transition from single words to bigrams: 30% of increment. \n",
            "\n",
            "<hr>10. Bigram matrix was used as a generator of weighted undirected graph for interpretation of Big Data by psychologists at glance. \n",
            "\n",
            "<hr>11. Open Ord force- directed layout algorithm — Gephi software makes transformation from 2D matrix to the tree topology graph. \n",
            "\n",
            "<hr>12. Weight of each node in matrix corresponds to the single word frequency while edge length is the inverse function of bigram frequency. \n",
            "\n",
            "<hr>13. Nodes are ranged according to the betweennes centrality and marked at the transformed graph. \n",
            "\n",
            "<hr>14. Relatively high BC- clustering in the test group is validated by Zip ’s law factor: 47 in Request against 25 in Responce Group, 1.9 times higher. \n",
            "\n",
            "<hr>15. Tags in figures are translated into English.# Year tag confirms a long- term stressful state, but is not interpreted as the Value.# Man,# Job,# Family/ Procreation are considered in relation to the Root Value:# Life. \n",
            "\n",
            "<hr>16. Nearest neighbours technics is applied: keywords extraction in relation to the given topic#Man value is almost fused with # Life root- attractor in Request. \n",
            "\n",
            "<hr>17. Bidirectional language associations, bigrams, are optimal semantics blocks and validates RFT assumptions. \n",
            "\n",
            "<hr>18. Bidirectional language associations, bigrams provide 30% of information increment, comparing with single words analysis. \n",
            "\n",
            "<hr>19. Ruminative attractors provide sufficient increase of centralization metric: betweennes centrality. \n",
            "\n",
            "<hr>20. sufficient increase of centralization metric: betweennes centrality is more sensitive than irrationality frequency despite the topic bias in Request. \n",
            "\n",
            "<hr>21. Instance analysis of text/ speech and normalized BC may give insights about the suicidal risks without applying more complicated techniques like neural networks( NNs). \n",
            "\n",
            "<hr>22. Sergey KamenshchikovFollowSep 29, 2019 · 6 min read   Tree of Keywords: graph analysis of semantics attractorsApplication domain. \n",
            "\n",
            "<hr>23. Tree of Keywords: graph analysis of semantics attractors Application domain. \n",
            "\n",
            "<hr>24. It seems that ruminative clusters and bigrams in Request sample give significant input as it was expected. \n",
            "\n",
            "<hr>25. It seems that ruminative clusters and bigrams in Request sample give significant input as it was expected. \n",
            "\n",
            "<hr>26. Nearest neighbours technics is applied: keywords extraction in relation to the given topic# Man value is almost fused with# Life root- attractor in the Request Group. \n",
            "\n",
            "<hr>27. It seems that D(Request)/D(Responce) and Zip ’s metrics are more sensitive and are closer to the trigger: rumination. \n",
            "\n",
            "<hr>28. It seems that D(Request)/D(Responce) and Zip ’s metrics are more sensitive and are closer to the trigger: rumination.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}