{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "paraphrase_tests.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SergeyKamenshchikov/CORONA/blob/master/paraphrase_tests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-2-uQE5ESYb"
      },
      "source": [
        "install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcZETyDqELt3"
      },
      "source": [
        "!pip3 install rouge\n",
        "!pip3 install xlsxwriter\n",
        "!pip3 install xlrd\n",
        "\n",
        "!pip3 install transformers\n",
        "!pip3 install sentencepiece\n",
        "\n",
        "!pip3 install textstat\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyBgf0SyEd-U"
      },
      "source": [
        "import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a85AIxiBEdlg"
      },
      "source": [
        "import pandas\n",
        "import json\n",
        "import numpy\n",
        "\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "import random\n",
        "\n",
        "import torch\n",
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "\n",
        "from rouge import Rouge\n",
        "rouge = Rouge()\n",
        "\n",
        "import textstat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0g7bHWQEgXa"
      },
      "source": [
        "get wiki corpus texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll8kRXoiDkZ0"
      },
      "source": [
        "#download wiki corpus by link\n",
        "!wget -O wiki_corpus https://drive.google.com/u/2/uc?id=1HvzyuQhM3VGMe5yiil-0vYk0fqvZM44F&export=download"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHcRlVZHE7eJ"
      },
      "source": [
        "#open corpus file and add texts to list\n",
        "df = pandas.read_excel('/content/wiki_corpus')\n",
        "\n",
        "wiki_corpus_texts=df[0].tolist()\n",
        "\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msE7QQgrFwbs"
      },
      "source": [
        "get arxiv corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqzM7wLtF9YN"
      },
      "source": [
        "#download arxiv corpus\n",
        "!wget --no-check-certificate -r -O arxiv_corpus.zip https://drive.google.com/u/0/uc?id=1b3rmCSIoh6VhD4HKWjI4HOW-cSwcwbeC&export=download"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQTsAZ31Hu7P"
      },
      "source": [
        "#unzip corpus - may take long due to big size\n",
        "!unzip /content/arxiv_corpus.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTIHSsp2JG2u"
      },
      "source": [
        "#open test file\n",
        "f=open(r'/content/arxiv-dataset/test.txt','r')\n",
        "corpus_lines = f.readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-5ED6pLJZ-C"
      },
      "source": [
        "#add text to list\n",
        "arxiv_corpus_texts=[]\n",
        "\n",
        "for line in corpus_lines:\n",
        "    \n",
        "    #line to json\n",
        "    data = json.loads(line)\n",
        "    \n",
        "    #get text of article\n",
        "    text=data['article_text']\n",
        "    text=' '.join(text)\n",
        "     \n",
        "    arxiv_corpus_texts.append(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qgv4lZuKNc4",
        "outputId": "03ffc82a-61be-4219-9df0-83eb2f07c44d"
      },
      "source": [
        "#normalize data\n",
        "\n",
        "target_length = 100\n",
        "\n",
        "arxiv_target_articles_texts=[ text for text in arxiv_corpus_texts if len(sent_tokenize(text))>target_length-1]\n",
        "\n",
        "print('Num of articles of desired length:',len(arxiv_target_articles_texts))\n",
        "\n",
        "arxiv_balanced_target_articles_texts=[' '.join(sent_tokenize(text)[:target_length]) for text in arxiv_target_articles_texts]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num of articles of desired length: 5740\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOzn7DI4Lb4L"
      },
      "source": [
        "Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH_DriPILdTS"
      },
      "source": [
        "#paraphrase model\n",
        "model_name = 'tuner007/pegasus_paraphrase'\n",
        "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyRvYRMiNny8"
      },
      "source": [
        "#testing parameters\n",
        "MAX_INPUT_LEN_K=1\n",
        "\n",
        "MAX_OUTPUT_LEN_K=1\n",
        "MIN_OUTPUT_LEN_K=1\n",
        "\n",
        "BEAMS=3\n",
        "\n",
        "COPRUS_SAMPLES=5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYJhBRkQLgGZ"
      },
      "source": [
        "Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqSAThodLgbE"
      },
      "source": [
        "def readability_ratio(text1,text2):\n",
        "  text1_syll=textstat.syllable_count(text1)\n",
        "  text2_syll=textstat.syllable_count(text2)\n",
        "  return(text2_syll/text1_syll*100)\n",
        "\n",
        "def pegasus_count_tokens(text):\n",
        "  #count number of tokens by pegasus_tokenizer\n",
        "  return len(tokenizer(text)['input_ids'])\n",
        "\n",
        "def paraphrase_sentence(input_text):\n",
        "  input_length = pegasus_count_tokens(input_text)\n",
        "  batch = tokenizer.prepare_seq2seq_batch([input_text],truncation=True,padding='longest', max_length=round(input_length*MAX_INPUT_LEN_K,0), return_tensors=\"pt\").to(torch_device)\n",
        "  translated = model.generate(**batch,max_length=round(input_length*MAX_OUTPUT_LEN_K,0),min_length=round(input_length*MIN_OUTPUT_LEN_K,0), num_beams=BEAMS, num_return_sequences=1, temperature=1.5 )\n",
        "  tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
        "  return tgt_text\n",
        "\n",
        "def paraphrase_text(text):\n",
        "  sentences=sent_tokenize(text)\n",
        "  new_sentences=[]\n",
        "  for sentence in sentences:\n",
        "    try:\n",
        "      new_sentence=paraphrase_sentence(sentence)[0]\n",
        "      new_sentences.append(new_sentence)\n",
        "    except IndexError:\n",
        "      print('Error: Sentence is too long!')\n",
        "      new_sentences.append(sentence)\n",
        "\n",
        "  new_text=' '.join(new_sentences)\n",
        "  return new_text\n",
        "\n",
        "def evaluate(corpus_texts):\n",
        "  rouge_L_scores=[]\n",
        "  readability_scores=[]\n",
        "\n",
        "  corpus_texts=random.sample(corpus_texts,COPRUS_SAMPLES)\n",
        "\n",
        "  i=0\n",
        "  for corpus_text in corpus_texts:\n",
        "    new_text=paraphrase_text(corpus_text)\n",
        "\n",
        "    rouge_L_scores.append(get_rouge_L_f(corpus_text,new_text))\n",
        "    readability_scores.append(readability_ratio(corpus_text,new_text))\n",
        "\n",
        "    #progress\n",
        "    i=i+1\n",
        "    print(i,' Texts processed')\n",
        "\n",
        "  #print results\n",
        "  print('\\n','-----')\n",
        "  print('Number of Texts: ', COPRUS_SAMPLES,'\\n')\n",
        "  print('ROUGE L median: ', numpy.median(rouge_L_scores))\n",
        "  print('ROUGE L deviation: ',numpy.std(rouge_L_scores),'\\n')\n",
        "  print('Readability median: ', numpy.median(readability_scores))\n",
        "  print('Readability deviation: ',numpy.std(readability_scores))\n",
        "\n",
        "def get_rouge_L_f(text1,text2):\n",
        "    scores = rouge.get_scores(text1, text2)\n",
        "    score_f=scores[0]['rouge-l']['f']\n",
        "    return(score_f)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOdOpccpLiNw"
      },
      "source": [
        "Testing paraphrase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuuYqtPFX15H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab953c27-aaee-41d6-e8a5-2583032fbbd8"
      },
      "source": [
        "%%time\n",
        "evaluate(wiki_corpus_texts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "1  Texts processed\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "2  Texts processed\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "3  Texts processed\n",
            "Error: Sentence is too long!\n",
            "4  Texts processed\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "5  Texts processed\n",
            "\n",
            " -----\n",
            "Number of Texts:  5 \n",
            "\n",
            "ROUGE L median:  0.7440982008600414\n",
            "ROUGE L deviation:  0.060311375467823926 \n",
            "\n",
            "Readability median:  94.66212379329926\n",
            "Readability deviation:  2.4900596922420073\n",
            "CPU times: user 17min 24s, sys: 8.46 s, total: 17min 33s\n",
            "Wall time: 17min 35s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2WF_DcvhTGm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db5437f6-08de-4941-921e-0460912499ff"
      },
      "source": [
        "%%time\n",
        "evaluate(arxiv_corpus_texts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "1  Texts processed\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "2  Texts processed\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "3  Texts processed\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "4  Texts processed\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "Error: Sentence is too long!\n",
            "5  Texts processed\n",
            "\n",
            " -----\n",
            "Number of Texts:  5 \n",
            "\n",
            "ROUGE L median:  0.7352941126554314\n",
            "ROUGE L deviation:  0.04083739028294236 \n",
            "\n",
            "Readability median:  97.77051129607611\n",
            "Readability deviation:  1.3961382521249197\n",
            "CPU times: user 1h 12min 9s, sys: 29.5 s, total: 1h 12min 38s\n",
            "Wall time: 1h 12min 44s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vRkFndIYhWv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}